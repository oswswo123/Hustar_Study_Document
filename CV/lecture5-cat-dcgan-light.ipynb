{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN with Cat-Face dataset\n",
    "\n",
    "- 아래 자료들을 참고했습니다.\n",
    "    - https://towardsdatascience.com/getting-started-with-gans-using-pytorch-78e7c22a14a5\n",
    "    - https://github.com/shubham7169/Projects/blob/master/CAT-dcgan.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 32\n",
    "batch_size = 128\n",
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5) # mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice\n",
    "- Load cat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size), # resize image to 64. - smaller edge will be 64 -> could be 64x64, 128x64, 128x64, ... \n",
    "    transforms.CenterCrop(image_size), # if the image is larger than 64x64, crop 64x64 from center. \n",
    "    transforms.ToTensor(), # PIL Image object to Tensor\n",
    "    transforms.Normalize(*stats)]) # normalize the image to have *stats mean and std\n",
    "\n",
    "train_ds = ImageFolder('./data/', transform=transform) # automatically apply transform on loading image - (Dataset)\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(img_tensors):\n",
    "    return img_tensors * stats[1][0] + stats[0][0] # make the values of result tensors have range of 0~1 : normal image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, nmax=64):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, _ in train_dl:\n",
    "    show_images(images, 64) # dataset check\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader(): # data = data.to(device) 를 생략할 수 있기 위함\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device) # dataloader to default device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "        \n",
    "        nn.Conv2d(3, 16, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        \n",
    "        \n",
    "        nn.Conv2d(16, 32, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        \n",
    "        \n",
    "        nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        \n",
    "        nn.Conv2d(64, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "        \n",
    "        nn.Flatten(),\n",
    "        nn.Sigmoid()) \n",
    "        # By applying Sigmoid, the result will have value in range of 0~1. We interpret the resulting value to be \"probability\"\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x    \n",
    "\n",
    "discriminator = Discriminator()\n",
    "discriminator = to_device(discriminator, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 32\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_size = latent_size\n",
    "        self.model = nn.Sequential(\n",
    "            \n",
    "        nn.ConvTranspose2d(latent_size, 64, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(True),\n",
    "        \n",
    "        nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(True),\n",
    "        \n",
    "        nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.ReLU(True),\n",
    "        \n",
    "        nn.ConvTranspose2d(16, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.Tanh())\n",
    "        # constantly upsamples random vector (latent) to generate image.\n",
    "        # Tanh to limit output value range.\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x  \n",
    "    \n",
    "generator = Generator(latent_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Generator Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xb = torch.randn(batch_size, latent_size, 1, 1) # random latent tensors\n",
    "fake_images = generator(xb)\n",
    "print(fake_images.shape)\n",
    "show_images(fake_images)\n",
    "# Generator is not trained. \n",
    "# It outputs random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = to_device(generator, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice\n",
    "- Implement discriminator loss\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}_{D} = \\mathbb{E}_{z \\sim N(0,I), x \\sim p_{data}(x)}[log(D(x)) + log(1 - D(G(z)))] $$\n",
    "$$  $$\n",
    "$$ or $$\n",
    "$$ \\mathcal{L}_{D} = \\frac{1}{N}\\sum_{i}^{N}[log(D(x_{i})) + log(1 - D(G(z_{i})))] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(real_images, opt_d):\n",
    "    # Clear discriminator gradients\n",
    "    opt_d.zero_grad()\n",
    "\n",
    "    # Pass real images through discriminator\n",
    "    real_preds = discriminator(real_images)\n",
    "    real_targets = torch.ones(real_images.size(0), 1, device=device)\n",
    "    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
    "    real_score = torch.mean(real_preds).item()\n",
    "    \n",
    "    # Generate fake images\n",
    "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
    "    fake_images = generator(latent)\n",
    "\n",
    "    # Pass fake images through discriminator\n",
    "    fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n",
    "    fake_preds = discriminator(fake_images)\n",
    "    fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n",
    "    fake_score = torch.mean(fake_preds).item()\n",
    "\n",
    "    # Update discriminator weights\n",
    "    loss = real_loss + fake_loss\n",
    "    loss.backward()\n",
    "    opt_d.step()\n",
    "    return loss.item(), real_score, fake_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice\n",
    "- Implement generator loss\n",
    "\n",
    "$$ \\mathcal{L}_{G} = \\mathbb{E}_{z \\sim N(0,I)}[log(1 - D(G(z)))] $$\n",
    "$$  $$\n",
    "$$ or $$\n",
    "$$ \\mathcal{L}_{G} = \\frac{1}{N} \\sum_{i}^{N}[log(1 - D(G(z_{i})))] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(opt_g):\n",
    "    # Clear generator gradients\n",
    "    opt_g.zero_grad()\n",
    "    \n",
    "    # Generate fake images\n",
    "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
    "    fake_images = generator(latent)\n",
    "    \n",
    "    # Try to fool the discriminator\n",
    "    preds = discriminator(fake_images)\n",
    "    targets = torch.ones(batch_size, 1, device=device)\n",
    "    loss = F.binary_cross_entropy(preds, targets)\n",
    "    \n",
    "    # Update generator weights\n",
    "    loss.backward()\n",
    "    opt_g.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = 'generated'\n",
    "os.makedirs(sample_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(index, latent_tensors, show=True):\n",
    "    fake_images = generator(latent_tensors)\n",
    "    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n",
    "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
    "    print('Saving', fake_fname)\n",
    "    if show:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(denorm(fake_images.cpu().detach()), nrow=8).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_latent = torch.randn(64, latent_size, 1, 1, device=device) # constant latent vector -> to see learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_samples(0, fixed_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, start_idx=1):\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Losses & scores\n",
    "    losses_g = []\n",
    "    losses_d = []\n",
    "    real_scores = []\n",
    "    fake_scores = []\n",
    "    \n",
    "    # Create optimizers\n",
    "    opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        generator.train()\n",
    "        discriminator.train()\n",
    "        for real_images, _ in tqdm(train_dl):\n",
    "            # Train discriminator\n",
    "            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n",
    "            # Train generator\n",
    "            loss_g = train_generator(opt_g)\n",
    "            \n",
    "        # Record losses & scores\n",
    "        losses_g.append(loss_g)\n",
    "        losses_d.append(loss_d)\n",
    "        real_scores.append(real_score)\n",
    "        fake_scores.append(fake_score)\n",
    "        \n",
    "        # Log losses & scores (last batch)\n",
    "        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
    "            epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n",
    "    \n",
    "        # Save generated images\n",
    "        with torch.no_grad():\n",
    "            generator.eval()\n",
    "            save_samples(epoch+start_idx, fixed_latent, show=True)\n",
    "            fake_images = generator(fixed_latent)\n",
    "            plt.clf()\n",
    "            fig, ax = plt.subplots(figsize=(8, 8))\n",
    "            ax.set_xticks([]); ax.set_yticks([])\n",
    "            ax.imshow(make_grid(denorm(fake_images.cpu().detach()), nrow=8).permute(1, 2, 0))\n",
    "            plt.show()\n",
    "        \n",
    "    return losses_g, losses_d, real_scores, fake_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fit(epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_g, losses_d, real_scores, fake_scores = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('./generated/generated-images-0060.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses_d, '-')\n",
    "plt.plot(losses_g, '-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Discriminator', 'Generator'])\n",
    "plt.title('Losses');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_scores, '-')\n",
    "plt.plot(fake_scores, '-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('score')\n",
    "plt.legend(['Real', 'Fake'])\n",
    "plt.title('Scores');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), 'generator.pkl')\n",
    "torch.save(discriminator.state_dict(), 'discriminator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
