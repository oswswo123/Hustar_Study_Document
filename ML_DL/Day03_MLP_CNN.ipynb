{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76938026-e7a1-406a-9cf4-0b664348eee0",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b8cd2a-d0de-422e-b61e-9f1f4b04deea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 14:34:38.357539: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018b2786-c121-4f80-85ec-0e696b24ad7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 14:34:40.517382: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2022-07-27 14:34:40.563960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:03:00.0 name: GeForce RTX 2080 computeCapability: 7.5\n",
      "coreClock: 1.71GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.23GiB/s\n",
      "2022-07-27 14:34:40.564613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: \n",
      "pciBusID: 0000:04:00.0 name: GeForce RTX 2080 computeCapability: 7.5\n",
      "coreClock: 1.71GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.23GiB/s\n",
      "2022-07-27 14:34:40.564636: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-07-27 14:34:40.566046: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-27 14:34:40.567266: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-27 14:34:40.567479: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-27 14:34:40.569045: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-27 14:34:40.569921: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-07-27 14:34:40.570051: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-10.2/lib64\n",
      "2022-07-27 14:34:40.570061: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-07-27 14:34:40.570782: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-27 14:34:40.596766: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2594040000 Hz\n",
      "2022-07-27 14:34:40.597495: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563819d0d330 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-07-27 14:34:40.597533: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-07-27 14:34:40.600345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-07-27 14:34:40.600369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      \n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train.astype(\"float32\"), x_test.astype(\"float32\")\n",
    "\n",
    "num_classes = 10\n",
    "num_feature = 784\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "x_train, x_test = tf.reshape(x_train, [-1, num_feature]), tf.reshape(x_test, [-1, num_feature])\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09847861-b70a-4f3e-b169-5a962a208a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train/255, x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df4e940b-092c-4bf2-aa0b-e1d0b55f3232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(128, activation=tf.nn.relu)\n",
    "        self.fc2 = tf.keras.layers.Dense(256, activation=tf.nn.relu)\n",
    "        self.out = tf.keras.layers.Dense(10)\n",
    "        \n",
    "    def call(self, x, is_training=False):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        if not is_training:\n",
    "            x = tf.nn.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16e7b018-7ccd-4b06-a568-85229a462116",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58d82b9a-3482-45bf-80d7-db3b0bd19817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(x, y):\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55724033-8a84-46cb-8caa-9f796bfbcaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, axis=1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e2b253d-2b45-44d2-9c25-2d1a39ca22b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.005\n",
    "optimizer = tf.optimizers.SGD(learning_rate=lr)\n",
    "\n",
    "def run_optimization(x, y):\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = neural_net(x, is_training=False)\n",
    "        loss = cross_entropy_loss(pred, y)\n",
    "    \n",
    "    parameters = neural_net.trainable_variables\n",
    "    # gradients = g.gradient(loss, [W, b])\n",
    "    gradients = g.gradient(loss, parameters)\n",
    "    optimizer.apply_gradients(zip(gradients, parameters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "238f5378-03c4-4623-9e5c-bd6849823789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1564a1d-4ffd-42bc-9129-0478751e1022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 4/40 [00:09<01:26,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 4\n",
      "loss : 2.2527626\n",
      "accuracy : 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▊                                   | 8/40 [00:19<01:18,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 8\n",
      "loss : 2.1001873\n",
      "accuracy : 0.415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 12/40 [00:29<01:08,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 12\n",
      "loss : 1.9273776\n",
      "accuracy : 0.685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 16/40 [00:39<00:58,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 16\n",
      "loss : 1.7823939\n",
      "accuracy : 0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 20/40 [00:49<00:49,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 20\n",
      "loss : 1.6981094\n",
      "accuracy : 0.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 24/40 [00:59<00:39,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 24\n",
      "loss : 1.7406522\n",
      "accuracy : 0.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 28/40 [01:09<00:29,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 28\n",
      "loss : 1.6878797\n",
      "accuracy : 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 32/40 [01:18<00:19,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 32\n",
      "loss : 1.6705561\n",
      "accuracy : 0.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 36/40 [01:28<00:09,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 36\n",
      "loss : 1.636029\n",
      "accuracy : 0.855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 40/40 [01:38<00:00,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40\n",
      "loss : 1.6501181\n",
      "accuracy : 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.shuffle(60000).batch(batch_size).prefetch(1)\n",
    "\n",
    "epoch = 40\n",
    "display_epoch = 4\n",
    "\n",
    "for epo in tqdm(range(1, epoch+1)):\n",
    "    for step, (batch_x, batch_y) in enumerate(train_data, 1):\n",
    "        run_optimization(batch_x, batch_y)\n",
    "    \n",
    "    if epo % display_epoch == 0:\n",
    "        pred = neural_net(batch_x)\n",
    "        loss = cross_entropy_loss(pred, batch_y)\n",
    "        acc = accuracy(pred, batch_y)\n",
    "        print(\"epoch :\", epo)\n",
    "        print(\"loss :\", loss.numpy())\n",
    "        print(\"accuracy :\", acc.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d9b3c2a-1f78-4f4a-ad17-119bba9852ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy :  0.82\n"
     ]
    }
   ],
   "source": [
    "pred = neural_net(x_test)\n",
    "print(\"Test Accuracy : \", accuracy(pred, y_test).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233a23c6-30b2-461d-8ce2-e32382f29e2d",
   "metadata": {},
   "source": [
    "## Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "102b22c0-2dd2-407a-98e6-9010833389f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9a3d6f7-3a5a-4af1-9ff1-fe01a9300716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_layer_test(filters, kernel_size, s=1, p=\"valid\", input_size=[1, 64, 64, 3]):\n",
    "    inputs = tf.random.normal(input_size)\n",
    "    print(\"input size : \", inputs.shape)\n",
    "    conv = tf.keras.layers.Conv2D(filters, kernel_size, strides=s, padding=p)\n",
    "    outputs = conv(inputs)\n",
    "    print(\"output size : \", outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "785ab181-44e4-4e41-8f07-fca2c9e9c5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size :  (1, 64, 64, 3)\n",
      "output size :  (1, 62, 62, 10)\n"
     ]
    }
   ],
   "source": [
    "convolution_layer_test(10, 3)  ## (W-F+2P)/S + 1  --> (64-3+2*0)/1 + 1 = 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db585525-90ca-4886-858a-3dffca98e5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size :  (1, 128, 128, 3)\n",
      "output size :  (1, 20, 20, 5)\n"
     ]
    }
   ],
   "source": [
    "convolution_layer_test(5, 11, s=6, p=\"valid\", input_size=[1, 128, 128, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff467738-12de-4bb7-bf7e-fccfdbd8c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling_layer_test(pool_size, s=1, p=\"valid\", input_size=[1, 64, 64, 3]):\n",
    "    inputs = tf.random.normal(input_size)\n",
    "    print(\"input size : \", inputs.shape)\n",
    "    pool = tf.keras.layers.MaxPooling2D(pool_size, strides=s, padding=p)\n",
    "    outputs = pool(inputs)\n",
    "    print(\"output size : \", outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cef78efd-54f8-4fd9-a0ec-d350d96ddaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size :  (1, 64, 64, 3)\n",
      "output size :  (1, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "pooling_layer_test(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59c123b-39dc-48f7-b738-56c5cb783100",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
