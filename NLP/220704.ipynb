{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "this_dir = pathlib.Path().parent.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Dataset\n",
    "from torchtext.data import Example\n",
    "from torchtext.data import Field\n",
    "\n",
    "\n",
    "class EnglishToGermanDataset(Dataset):\n",
    "\n",
    "    def __init__(self, corpus, processors):\n",
    "        examples = []\n",
    "        for bitext in corpus:\n",
    "            examples.append(Example.fromlist(bitext, processors))\n",
    "        super().__init__(examples, processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{this_dir}/data/train.src\") as src_file:\n",
    "\twith open(f\"{this_dir}/data/train.tgt\") as tgt_file:\n",
    "\t\tcorpus = []\n",
    "\t\tfor (src_seq, tgt_seq) in zip(src_file, tgt_file):\n",
    "\t\t\tcorpus.append(((\"src\", src_seq), (\"tgt\", tgt_seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "from sentencepiece import SentencePieceProcessor\n",
    "from sentencepiece import SentencePieceTrainer\n",
    "\n",
    "SentencePieceTrainer.train(input=f\"{this_dir}/data/train.src\",\n",
    "\t\t\t\t\t\t   model_prefix=\"spm_src\", vocab_size=5000)\n",
    "src_tokenizer = SentencePieceProcessor(model_file=\"./spm_src.model\")\n",
    "src_bpe_func = lambda tokens: src_tokenizer.encode(\" \".join(tokens), out_type=str)\n",
    "\n",
    "SentencePieceTrainer.train(input=f\"{this_dir}/data/train.tgt\",\n",
    "\t\t\t\t\t\t   model_prefix=\"spm_tgt\", vocab_size=5000)\n",
    "tgt_tokenizer = SentencePieceProcessor(model_file=\"./spm_tgt.model\")\n",
    "tgt_bpe_func = lambda tokens: tgt_tokenizer.encode(\" \".join(tokens), out_type=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processors = list()\n",
    "processors.append((\"src\", Field(sequential=True, use_vocab=True,\n",
    "\t\t\t  \t                preprocessing=src_bpe_func,\n",
    "\t\t\t\t\t\t\t\tpad_token=\"<pad>\", unk_token=\"<unk>\",\n",
    "\t\t\t\t\t\t\t\tbatch_first=True)))\n",
    "processors.append((\"tgt\", Field(sequential=True, use_vocab=True,\n",
    "\t\t\t\t\t\t\t\tinit_token=\"<bos>\", eos_token=\"<eos>\",\n",
    "\t\t\t\t\t\t\t    preprocessing=tgt_bpe_func, pad_token=\"<pad>\",\n",
    "\t\t\t\t  \t\t\t\tunk_token=\"<unk>\", batch_first=True)))\n",
    "\n",
    "dataset = EnglishToGermanDataset(corpus, processors)\n",
    "for processor in processors:\n",
    "\tprocessor[1].build_vocab(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "MAX_ITER = 3\n",
    "\n",
    "\n",
    "def ibm_model(examples, src_vocab, tgt_vocab):\n",
    "    alignment = np.full((len(src_vocab), len(tgt_vocab)),\n",
    "                        1 / len(src_vocab), dtype=float)\n",
    "    count = 0\n",
    "    while count <= MAX_ITER:\n",
    "        print(f\"{count}번째 iteration:\")\n",
    "        maximization = np.full((len(src_vocab), len(tgt_vocab)), 0, dtype=float)\n",
    "        corp_total_like = np.full((len(tgt_vocab),), 0, dtype=float)\n",
    "        # 시퀀스 하나씩 처리합니다.\n",
    "        for example in tqdm.tqdm(examples, desc=\"P(src -> tgt)의 기댓값을 추정 중입니다.\"):\n",
    "\n",
    "            # 주어진 시퀀스를 대상으로 sum(j, P(src_i -> tgt_j))를 찾습니다.\n",
    "            ex_total_like = np.full((len(example.src),), 0, dtype=float)\n",
    "            for i, src_tok in enumerate(example.src):\n",
    "                src_tok_ind = src_vocab.stoi[src_tok]\n",
    "                ex_total_like[i] = 0\n",
    "                for tgt_tok in example.tgt:\n",
    "                    tgt_tok_ind = tgt_vocab.stoi[tgt_tok]\n",
    "                    ex_total_like[i] += alignment[src_tok_ind][tgt_tok_ind]\n",
    "\n",
    "            # 주어진 시퀀스에서 영어 토큰과 독일어 토큰을 짝짓습니다 (Expectation).\n",
    "            # P(src_i -> tgt_j)를 추정하는 단계입니다.\n",
    "            for i, src_tok in enumerate(example.src):\n",
    "                src_tok_ind = src_vocab.stoi[src_tok]\n",
    "                for tgt_tok in example.tgt:\n",
    "                    tgt_tok_ind = tgt_vocab.stoi[tgt_tok]\n",
    "                    # P(src_i -> tgt_j)를 위에서 찾은 sum(j, P(src_i -> tgt_j))로\n",
    "                    # 나누어 정규화해 줍니다.\n",
    "                    expectation = (alignment[src_tok_ind][tgt_tok_ind]\n",
    "                                   / ex_total_like[i])\n",
    "\n",
    "                    # P(src_i -> tgt_j)를 코퍼스 전체를 대상으로 모두 찾아 더해줍니다.\n",
    "                    maximization[src_tok_ind][tgt_tok_ind] += expectation\n",
    "                    corp_total_like[tgt_tok_ind] += expectation\n",
    "\n",
    "        # P(src_i -> tgt_j)를 sum(all, P(src_i -> tgt_all))로 나누어 정규화해 줍니다. \n",
    "        for tgt_tok_ind in tqdm.tqdm(\n",
    "            range(len(tgt_vocab)),\n",
    "            desc=\"코퍼스에서 (src -> tgt)를 모두 찾아서 그 빈도에 비례해 P(src -> tgt)의 기댓값을 최대화합니다.\",\n",
    "        ):\n",
    "            for src_tok_ind in range(len(src_vocab)):\n",
    "                if maximization[src_tok_ind][tgt_tok_ind] != 0 :\n",
    "                    alignment[src_tok_ind][tgt_tok_ind] = (\n",
    "                        maximization[src_tok_ind][tgt_tok_ind]\n",
    "                        / corp_total_like[tgt_tok_ind]\n",
    "                    )\n",
    "\n",
    "        count += 1\n",
    "    return alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(examples, src_vocab, tgt_vocab):\n",
    "    # IBM 모델 1을 사용하겠습니다.\n",
    "    ibm_model_1  = ibm_model(examples, src_vocab, tgt_vocab)\n",
    "    model = dict()\n",
    "    for src_tok_ind in range(len(src_vocab)):\n",
    "        max_like = float(\"-inf\")\n",
    "        for tgt_tok_ind in range(len(tgt_vocab)):\n",
    "            this_like = ibm_model_1[src_tok_ind][tgt_tok_ind]\n",
    "            if this_like > max_like:\n",
    "                max_like = this_like\n",
    "                max_like_tok = tgt_vocab.itos[tgt_tok_ind]\n",
    "        model[src_vocab.itos[src_tok_ind]] = max_like_tok\n",
    "    np.save(\"data/model\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def translate(src_seq) -> float:\n",
    "    model = np.load(\"data/model.npy\", allow_pickle=True).item()\n",
    "    translation = dict()\n",
    "    for src_tok in src_seq:\n",
    "        translation[src_tok] = model[src_tok]\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(dataset.examples, processors[0][1].vocab, processors[1][1].vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_seq = src_tokenizer.encode(\n",
    "\t\"I hope that the fire we both made still burns a little in you\",\n",
    "\tout_type=str)\n",
    "translation = translate(src_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "table = pandas.Series(translation)\n",
    "table.index.name = \"영어 -> 독일어\"\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d39d7678f083d4112fab20b5fd04b42951bda7bf43fd2924e491550025a0a7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
